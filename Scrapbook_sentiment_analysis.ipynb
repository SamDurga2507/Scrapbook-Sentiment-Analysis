{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H4xm24pwcmaG"
      },
      "outputs": [],
      "source": [
        "# sentiment scrapbook analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize #tokenization\n",
        "from nltk.corpus import stopwords #stop words remove\n",
        "from nltk.stem.snowball import SnowballStemmer # stemming process\n",
        "from sklearn.naive_bayes import MultinomialNB # naive bayes model\n",
        "from sklearn.feature_extraction.text import CountVectorizer #bag of words\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "s_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    reduce_stopW = [word for word in tokens if word.lower() not in stopwords.words('english')]\n",
        "    steming_words = [s_stemmer.stem(word) for word in reduce_stopW]\n",
        "    return \" \".join(steming_words)\n",
        "\n",
        "def train_sentiment_model(training_data):\n",
        "    filtered_words = [preprocess_sentence(sent) for sent, _ in training_data]\n",
        "\n",
        "    model = MultinomialNB()\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(filtered_words)\n",
        "    y = [label for _, label in training_data]\n",
        "\n",
        "    model.fit(X, y)\n",
        "    return model, vectorizer\n",
        "\n",
        "def predict_sentiment(model, vectorizer, sentence):\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    sentence_vectorized = vectorizer.transform([preprocessed_sentence])\n",
        "    prediction = model.predict(sentence_vectorized)\n",
        "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    training_data= [\n",
        "    (\"The weather is fantastic today, ideal for outdoor activities\", 1),\n",
        "    (\"The new cafe in town serves amazing coffee and pastries\", 1),\n",
        "    (\"I completed a challenging project successfully, feeling accomplished\", 1),\n",
        "    (\"The concert last night was electrifying and unforgettable\", 1),\n",
        "    (\"The customer support team was responsive and helpful\", 1),\n",
        "    (\"I had a frustrating experience with the delayed flight and lost luggage\", 0),\n",
        "    (\"The traffic jam on the way to work was unbearable, causing stress\", 0),\n",
        "    (\"The restaurant's food quality was disappointing and overpriced\", 0),\n",
        "    (\"I couldn't find my keys and was late for an important meeting, feeling annoyed\", 0),\n",
        "    (\"The movie I watched was boring and lacked any excitement\", 0),\n",
        "    (\"The unexpected rain ruined my outdoor plans, feeling disappointed\", 0),\n",
        "    (\"I received negative feedback on my proposal, feeling disheartened\", 0),\n",
        "    (\"The hiking trail was poorly marked, leading to confusion and frustration\", 0),\n",
        "    (\"The comedy show I attended was not amusing, feeling let down\", 0),\n",
        "    (\"I discovered a hidden gem of a bookstore, feeling delighted\", 1),\n",
        "    (\"The surprise party thrown by my friends made me incredibly happy\", 1),\n",
        "    (\"The novel I read was gripping and kept me hooked until the end\", 1),\n",
        "    (\"I faced technical issues during an online meeting, feeling frustrated\", 0),\n",
        "    (\"The sunrise from the mountaintop was breathtaking, feeling awe-inspired\", 1),\n",
        "    (\"The service at the new restaurant was slow and inattentive\", 0),\n",
        "    (\"I received a heartfelt letter from a loved one, feeling touched\", 1),\n",
        "    (\"The long wait at the doctor's office was tiresome and irritating\", 0),\n",
        "    (\"The beach vacation was relaxing and rejuvenating\", 1),\n",
        "    (\"The presentation at the conference was dull and uninspiring\", 0),\n",
        "    (\"I successfully completed a challenging workout, feeling accomplished\", 1),\n",
        "    (\"The software update caused my computer to crash, feeling frustrated\", 0),\n",
        "    (\"The traffic on the highway was smooth and hassle-free\", 1),\n",
        "    (\"I accidentally deleted an important file, feeling anxious about the loss\", 0),\n",
        "    (\"The museum exhibit was informative and engaging\", 1),\n",
        "    (\"The concert tickets were sold out, feeling disappointed\", 0),\n",
        "    (\"I found a wallet on the street and returned it to the owner, feeling proud\", 1),\n",
        "    (\"The novel I read was thought-provoking and insightful\", 1),\n",
        "    (\"The unexpected bonus at work made me ecstatic\", 1),\n",
        "    (\"The train was delayed, causing inconvenience and frustration\", 0),\n",
        "    (\"I explored a new city and fell in love with its charm\", 1),\n",
        "    (\"The sports event was boring and lacked excitement\", 0),\n",
        "    (\"I received a thoughtful gift from a friend, feeling grateful\", 1),\n",
        "    (\"The restaurant's atmosphere was lively, and the food was delicious\", 1),\n",
        "    (\"The conference had informative sessions and valuable networking opportunities\", 1),\n",
        "    (\"The car broke down on the highway, causing stress and delay\", 0),\n",
        "    (\"I tried a new recipe, and it turned out to be a culinary masterpiece\", 1),\n",
        "    (\"The customer service at the store was unhelpful and rude\", 0),\n",
        "    (\"I found a surprise discount at the checkout, making me happy\", 1),\n",
        "    (\"The play I attended was entertaining and captivating\", 1),\n",
        "    (\"The flight was canceled, leading to frustration and inconvenience\", 0),\n",
        "    (\"I enjoyed a peaceful day at the spa, feeling relaxed and rejuvenated\", 1),\n",
        "    (\"The budget proposal was rejected, feeling disheartened\", 0),\n",
        "    (\"I received constructive feedback on my project, appreciating the input\", 1),\n",
        "    (\"The public transportation was on time and efficient today\", 1),\n",
        "    (\"I got stuck in an elevator for an hour, a terrifying experience\", 0),\n",
        "    (\"The city skyline at night was mesmerizing, feeling enchanted\", 1),\n",
        "    (\"The play I watched was dull and uninteresting\", 0),\n",
        "    (\"I missed my connecting flight, causing inconvenience and frustration\", 0),\n",
        "    (\"The beach vacation was perfect, with sunny weather and clear waters\", 1),\n",
        "    (\"The political debate on TV was polarizing and exhausting\", 0),\n",
        "    (\"I attended an inspiring motivational seminar, feeling motivated\", 1),\n",
        "    (\"The customer support hotline was unresponsive and frustrating\", 0),\n",
        "    (\"I discovered a new hiking trail with breathtaking views\", 1),\n",
        "    (\"The company announced a bonus for all employees, making me happy\", 1),\n",
        "    (\"The plumbing issue at home caused stress and inconvenience\", 0),\n",
        "    (\"I accidentally spilled coffee on my laptop, feeling anxious about the damage\", 0),\n",
        "    (\"The music festival was energetic and vibrant\", 1),\n",
        "    ]\n",
        "\n",
        "\n",
        "    trained_model, trained_vectorizer = train_sentiment_model(training_data)\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter a sentence (type 'exit' to end): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        result = predict_sentiment(trained_model, trained_vectorizer, user_input)\n",
        "        print(f\"Predicted sentiment: {result}\")\n"
      ],
      "metadata": {
        "id": "107WoOpHc6qw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}